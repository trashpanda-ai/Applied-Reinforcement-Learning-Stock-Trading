{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db5960cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-08T12:48:01.463529Z",
     "start_time": "2023-09-08T12:48:00.140075Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "best_stocks = ['NVDA', 'DIS', 'KO', 'MO', 'BABA', 'MA', 'V', 'JPM', 'PG', 'TSM', 'META', 'TSLA', 'GOOGL', 'AMZN', 'MSFT', 'AAPL']\n",
    "more_stocks = ['ABBV', 'PEP', 'CRM', 'PFE', 'NFLX', 'AMD', 'ABT', 'PM', 'BA', 'NKE', 'GS', 'T']\n",
    "even_more = ['C', 'MU']\n",
    "\n",
    "months = ['2021-11', '2021-12', '2022-01', '2022-02', '2022-03', '2022-04', '2022-05', '2022-06', '2022-07', '2022-08',\n",
    "          '2022-09', '2022-10', '2022-11', '2022-12', '2023-01', '2023-02', '2023-03', '2023-04', '2023-05', '2023-06',\n",
    "          '2023-07', '2023-08']\n",
    "desired_times = [\"09:30:00\", \"10:00:00\", \"11:00:00\", \"12:00:00\", \"13:00:00\", \"14:00:00\", \"15:00:00\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-06T20:20:55.764658Z",
     "start_time": "2023-09-06T20:20:55.759330Z"
    }
   },
   "id": "2e96fec31eae5ea3"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Create a directory named 'stock_data' if it doesn't exist\n",
    "folder_name = \"stock_data\"\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-06T20:14:17.622922Z",
     "start_time": "2023-09-06T20:14:17.618651Z"
    }
   },
   "id": "9508aa458ae99e3"
  },
  {
   "cell_type": "markdown",
   "id": "b2c14313",
   "metadata": {},
   "source": [
    "### Alpha Vantage API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5267f070",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-03T16:43:44.446550Z",
     "start_time": "2023-09-03T16:42:49.881974Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for C in month 2021-11 saved to stock_data/C.csv\n",
      "Data for C in month 2021-12 saved to stock_data/C.csv\n",
      "Data for C in month 2022-01 saved to stock_data/C.csv\n",
      "Data for C in month 2022-02 saved to stock_data/C.csv\n",
      "Data for C in month 2022-03 saved to stock_data/C.csv\n",
      "Data for C in month 2022-04 saved to stock_data/C.csv\n",
      "Data for C in month 2022-05 saved to stock_data/C.csv\n",
      "Data for C in month 2022-06 saved to stock_data/C.csv\n",
      "Data for C in month 2022-07 saved to stock_data/C.csv\n",
      "Data for C in month 2022-08 saved to stock_data/C.csv\n",
      "Data for C in month 2022-09 saved to stock_data/C.csv\n",
      "Data for C in month 2022-10 saved to stock_data/C.csv\n",
      "Data for C in month 2022-11 saved to stock_data/C.csv\n",
      "Data for C in month 2022-12 saved to stock_data/C.csv\n",
      "Data for C in month 2023-01 saved to stock_data/C.csv\n",
      "Data for C in month 2023-02 saved to stock_data/C.csv\n",
      "Data for C in month 2023-03 saved to stock_data/C.csv\n",
      "Data for C in month 2023-04 saved to stock_data/C.csv\n",
      "Data for C in month 2023-05 saved to stock_data/C.csv\n",
      "Data for C in month 2023-06 saved to stock_data/C.csv\n",
      "Data for C in month 2023-07 saved to stock_data/C.csv\n",
      "Data for C in month 2023-08 saved to stock_data/C.csv\n",
      "Data for MU in month 2021-11 saved to stock_data/MU.csv\n",
      "Data for MU in month 2021-12 saved to stock_data/MU.csv\n",
      "Data for MU in month 2022-01 saved to stock_data/MU.csv\n",
      "Data for MU in month 2022-02 saved to stock_data/MU.csv\n",
      "Data for MU in month 2022-03 saved to stock_data/MU.csv\n",
      "Data for MU in month 2022-04 saved to stock_data/MU.csv\n",
      "Data for MU in month 2022-05 saved to stock_data/MU.csv\n",
      "Data for MU in month 2022-06 saved to stock_data/MU.csv\n",
      "Data for MU in month 2022-07 saved to stock_data/MU.csv\n",
      "Data for MU in month 2022-08 saved to stock_data/MU.csv\n",
      "Data for MU in month 2022-09 saved to stock_data/MU.csv\n",
      "Data for MU in month 2022-10 saved to stock_data/MU.csv\n",
      "Data for MU in month 2022-11 saved to stock_data/MU.csv\n",
      "Data for MU in month 2022-12 saved to stock_data/MU.csv\n",
      "Data for MU in month 2023-01 saved to stock_data/MU.csv\n",
      "Data for MU in month 2023-02 saved to stock_data/MU.csv\n",
      "Data for MU in month 2023-03 saved to stock_data/MU.csv\n",
      "Data for MU in month 2023-04 saved to stock_data/MU.csv\n",
      "Data for MU in month 2023-05 saved to stock_data/MU.csv\n",
      "Data for MU in month 2023-06 saved to stock_data/MU.csv\n",
      "Data for MU in month 2023-07 saved to stock_data/MU.csv\n",
      "Data for MU in month 2023-08 saved to stock_data/MU.csv\n"
     ]
    }
   ],
   "source": [
    "for stock in even_more:\n",
    "    combined_data = pd.DataFrame()  # Initialize an empty DataFrame to store combined data\n",
    "\n",
    "    for month in months:\n",
    "        url = f'https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY&symbol={stock}&interval=30min&month={month}&outputsize=full&extended_hours=false&apikey=J2KWBMQJTFXBCSEB'\n",
    "        r = requests.get(url)\n",
    "        data = r.json()\n",
    "\n",
    "        # Extract the time series data\n",
    "        df = pd.DataFrame(data['Time Series (30min)']).T\n",
    "        combined_data = pd.concat([combined_data, df])\n",
    "\n",
    "        # Filter data for the desired timestamps\n",
    "        combined_data = combined_data[combined_data.index.str.split(\" \").str[1].isin(desired_times)]\n",
    "\n",
    "        # Create or overwrite a CSV file for each stock inside the 'stocks_data' folder\n",
    "        file_path = os.path.join(folder_name, f\"{stock}.csv\")\n",
    "        with open(file_path, \"w\", newline='') as csvfile:\n",
    "            csvwriter = csv.writer(csvfile)\n",
    "\n",
    "            # Write the header\n",
    "            csvwriter.writerow([\"Time\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"])\n",
    "\n",
    "            for index, row in combined_data.iterrows():\n",
    "                # Rename 09:30:00 to 09:00:00\n",
    "                if index.split(\" \")[1] == \"09:30:00\":\n",
    "                    index = index.replace(\"09:30:00\", \"09:00:00\")\n",
    "                # Write the filtered data\n",
    "                csvwriter.writerow(\n",
    "                    [index, row[\"1. open\"], row[\"2. high\"], row[\"3. low\"], row[\"4. close\"], row[\"5. volume\"]])\n",
    "\n",
    "        print(f\"Data for {stock} in month {month} saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Request links"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "656327c8f6b8654b"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY&symbol=VIXY&interval=30min&outputsize=full&extended_hours=false&apikey=J2KWBMQJTFXBCSEB\n",
    "# https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY&symbol=VIXY&interval=30min&month=2021-11&outputsize=full&extended_hours=false&apikey=J2KWBMQJTFXBCSEB\n",
    "\n",
    "### VIX ###\n",
    "# https://www.alphavantage.co/query?function=SYMBOL_SEARCH&keywords=VIX&apikey=J2KWBMQJTFXBCSEB\n",
    "# https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY&symbol=VIXY&interval=30min&extended_hours=false&apikey=J2KWBMQJTFXBCSEB\n",
    "# https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol=IBM&outputsize=full&apikey=J2KWBMQJTFXBCSEB"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T13:55:16.140312Z",
     "start_time": "2023-09-03T13:55:16.122638Z"
    }
   },
   "id": "8ad34125be0e4192"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### VIXY Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "47ff50d5fca6fc5f"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for VIXY in month 2021-11 saved to stock_data/VIXY.csv\n",
      "Data for VIXY in month 2021-12 saved to stock_data/VIXY.csv\n",
      "Data for VIXY in month 2022-01 saved to stock_data/VIXY.csv\n",
      "Data for VIXY in month 2022-02 saved to stock_data/VIXY.csv\n",
      "Data for VIXY in month 2022-03 saved to stock_data/VIXY.csv\n",
      "Data for VIXY in month 2022-04 saved to stock_data/VIXY.csv\n",
      "Data for VIXY in month 2022-05 saved to stock_data/VIXY.csv\n",
      "Data for VIXY in month 2022-06 saved to stock_data/VIXY.csv\n",
      "Data for VIXY in month 2022-07 saved to stock_data/VIXY.csv\n",
      "Data for VIXY in month 2022-08 saved to stock_data/VIXY.csv\n",
      "Data for VIXY in month 2022-09 saved to stock_data/VIXY.csv\n",
      "Data for VIXY in month 2022-10 saved to stock_data/VIXY.csv\n",
      "Data for VIXY in month 2022-11 saved to stock_data/VIXY.csv\n",
      "Data for VIXY in month 2022-12 saved to stock_data/VIXY.csv\n",
      "Data for VIXY in month 2023-01 saved to stock_data/VIXY.csv\n",
      "Data for VIXY in month 2023-02 saved to stock_data/VIXY.csv\n",
      "Data for VIXY in month 2023-03 saved to stock_data/VIXY.csv\n",
      "Data for VIXY in month 2023-04 saved to stock_data/VIXY.csv\n",
      "Data for VIXY in month 2023-05 saved to stock_data/VIXY.csv\n",
      "Data for VIXY in month 2023-06 saved to stock_data/VIXY.csv\n",
      "Data for VIXY in month 2023-07 saved to stock_data/VIXY.csv\n",
      "Data for VIXY in month 2023-08 saved to stock_data/VIXY.csv\n"
     ]
    }
   ],
   "source": [
    "combined_data = pd.DataFrame()  # Initialize an empty DataFrame to store combined data\n",
    "\n",
    "for month in months:\n",
    "    url = f'https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY&symbol=VIXY&interval=30min&month={month}&outputsize=full&extended_hours=false&apikey=J2KWBMQJTFXBCSEB'\n",
    "    r = requests.get(url)\n",
    "    data = r.json()\n",
    "\n",
    "    # Extract the time series data\n",
    "    df = pd.DataFrame(data['Time Series (30min)']).T\n",
    "    combined_data = pd.concat([combined_data, df])\n",
    "\n",
    "    # Filter data for the desired timestamps\n",
    "    combined_data = combined_data[combined_data.index.str.split(\" \").str[1].isin(desired_times)]\n",
    "\n",
    "    # Filter data for the desired timestamps\n",
    "    df = df[df.index.str.split(\" \").str[1].isin(desired_times)]\n",
    "\n",
    "    # Create or overwrite a CSV file for each stock inside the 'stocks_data' folder\n",
    "    file_path = os.path.join(folder_name, f\"VIXY.csv\")\n",
    "    with open(file_path, \"w\", newline='') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "\n",
    "        # Write the header\n",
    "        csvwriter.writerow([\"Time\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"])\n",
    "\n",
    "        for index, row in combined_data.iterrows():\n",
    "            # Rename 09:30:00 to 09:00:00\n",
    "            if index.split(\" \")[1] == \"09:30:00\":\n",
    "                index = index.replace(\"09:30:00\", \"09:00:00\")\n",
    "            # Write the filtered data\n",
    "            csvwriter.writerow(\n",
    "                [index, row[\"1. open\"], row[\"2. high\"], row[\"3. low\"], row[\"4. close\"], row[\"5. volume\"]])\n",
    "\n",
    "    print(f\"Data for VIXY in month {month} saved to {file_path}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-03T16:20:44.413840Z",
     "start_time": "2023-09-03T16:20:24.076041Z"
    }
   },
   "id": "59068bce13ac24e8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Daily Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df2413da4aa407d"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Create a directory named 'stock_data' if it doesn't exist\n",
    "folder_name = \"stock_data_daily\"\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-08T12:48:08.233750Z",
     "start_time": "2023-09-08T12:48:08.224798Z"
    }
   },
   "id": "9690f46d99a94d7f"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for NVDA saved to stock_data_daily/NVDA.csv\n",
      "Data for DIS saved to stock_data_daily/DIS.csv\n",
      "Data for KO saved to stock_data_daily/KO.csv\n",
      "Data for MO saved to stock_data_daily/MO.csv\n",
      "Data for BABA saved to stock_data_daily/BABA.csv\n",
      "Data for MA saved to stock_data_daily/MA.csv\n",
      "Data for V saved to stock_data_daily/V.csv\n",
      "Data for JPM saved to stock_data_daily/JPM.csv\n",
      "Data for PG saved to stock_data_daily/PG.csv\n",
      "Data for TSM saved to stock_data_daily/TSM.csv\n",
      "Data for META saved to stock_data_daily/META.csv\n",
      "Data for TSLA saved to stock_data_daily/TSLA.csv\n",
      "Data for GOOGL saved to stock_data_daily/GOOGL.csv\n",
      "Data for AMZN saved to stock_data_daily/AMZN.csv\n",
      "Data for MSFT saved to stock_data_daily/MSFT.csv\n",
      "Data for AAPL saved to stock_data_daily/AAPL.csv\n"
     ]
    }
   ],
   "source": [
    "start_date = \"2021-11-24\"\n",
    "end_date = \"2023-08-31\"\n",
    "    \n",
    "for stock in best_stocks:\n",
    "    url = f'https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol={stock}&outputsize=full&apikey=J2KWBMQJTFXBCSEB'\n",
    "    r = requests.get(url)\n",
    "    data = r.json()\n",
    "\n",
    "    # Extract the time series data\n",
    "    df = pd.DataFrame(data['Time Series (Daily)']).T\n",
    "\n",
    "    # Filter data for the desired date range\n",
    "    df = df[(df.index >= start_date) & (df.index <= end_date)]\n",
    "\n",
    "    # Create or overwrite a CSV file for each stock inside the 'stocks_data' folder\n",
    "    file_path = os.path.join(folder_name, f\"{stock}.csv\")\n",
    "    with open(file_path, \"w\", newline='') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "\n",
    "        # Write the header\n",
    "        csvwriter.writerow([\"Time\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"])\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            # Write the filtered data\n",
    "            csvwriter.writerow(\n",
    "                [index, row[\"1. open\"], row[\"2. high\"], row[\"3. low\"], row[\"4. close\"], row[\"5. volume\"]])\n",
    "\n",
    "    print(f\"Data for {stock} saved to {file_path}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-06T20:26:40.860790Z",
     "start_time": "2023-09-06T20:26:15.565183Z"
    }
   },
   "id": "52c15c2ba23ee1b0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### VIXY Data Daily"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e651a047a79f9db1"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for VIXY saved to stock_data_daily/VIXY.csv\n"
     ]
    }
   ],
   "source": [
    "start_date = \"2021-11-24\"\n",
    "end_date = \"2023-08-31\"\n",
    "    \n",
    "url = f'https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol=VIXY&outputsize=full&apikey=J2KWBMQJTFXBCSEB'\n",
    "r = requests.get(url)\n",
    "data = r.json()\n",
    "\n",
    "# Extract the time series data\n",
    "df = pd.DataFrame(data['Time Series (Daily)']).T\n",
    "\n",
    "# Filter data for the desired date range\n",
    "df = df[(df.index >= start_date) & (df.index <= end_date)]\n",
    "\n",
    "# Create or overwrite a CSV file for each stock inside the 'stocks_data' folder\n",
    "file_path = os.path.join(folder_name, \"VIXY.csv\")\n",
    "with open(file_path, \"w\", newline='') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "\n",
    "    # Write the header\n",
    "    csvwriter.writerow([\"Time\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"])\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        # Write the filtered data\n",
    "        csvwriter.writerow(\n",
    "            [index, row[\"1. open\"], row[\"2. high\"], row[\"3. low\"], row[\"4. close\"], row[\"5. volume\"]])\n",
    "\n",
    "print(f\"Data for VIXY saved to {file_path}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-08T12:48:13.893367Z",
     "start_time": "2023-09-08T12:48:12.523082Z"
    }
   },
   "id": "c8e16d66e0603aa9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "976dbe36a3e86e94"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
